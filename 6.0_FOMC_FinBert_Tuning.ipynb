{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,RandomSampler, SequentialSampler,TensorDataset\n",
    "from transformers import BertTokenizer, AdamW ,BertModel, BertPreTrainedModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "class CustomFinBERT(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        # Load the pre-trained BERT model\n",
    "        self.bert = BertModel(config)\n",
    "\n",
    "        # Define custom feedforward layers\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(config.hidden_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 3)  # Output layer for 3 classes\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        # Get the output from the BERT model\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[1]  # Use pooled output\n",
    "\n",
    "        # Pass through the custom layers\n",
    "        x = self.dropout(sequence_output)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = nn.ReLU()(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Prepare the dataset\n",
    "def encode_texts(tokenizer, texts, max_length=512):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "\n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,  # Include token type ids\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "        token_type_ids.append(encoded['token_type_ids'])  # Append token type ids\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    token_type_ids = torch.cat(token_type_ids, dim=0)  # Concatenate token type ids\n",
    "\n",
    "    return input_ids, attention_masks, token_type_ids\n",
    "\n",
    "def train(model, train_dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        # Move batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Forward pass, include token_type_ids\n",
    "        outputs = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, b_labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    return avg_train_loss\n",
    "\n",
    "def evaluate(model, validation_dataloader, device):\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        # Move batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, include token_type_ids\n",
    "            outputs = model(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_input_mask)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss()(outputs, b_labels)\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1).flatten()\n",
    "        total_eval_accuracy += (preds == b_labels).cpu().numpy().mean()\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    return avg_val_loss, avg_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomFinBERT were not initialized from the model checkpoint at yiyanghkust/finbert-tone and are newly initialized: ['fc3.weight', 'fc2.weight', 'fc4.weight', 'fc1.weight', 'fc4.bias', 'fc3.bias', 'fc2.bias', 'fc1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "model = CustomFinBERT.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-pretrain')\n",
    "#Load the dataset\n",
    "df = pd.read_csv('ft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['sentence'].values\n",
    "labels = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-40938864/ipykernel_3217969/3311766473.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# Encode the dataset\n",
    "input_ids, attention_masks, token_type_ids = encode_texts(tokenizer, texts)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Split the dataset\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=42, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=42, test_size=0.1)\n",
    "train_token_types, validation_token_types, _, _ = train_test_split(token_type_ids, labels, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader\n",
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_token_types, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_token_types, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-05.\n",
      "======== Epoch 1 / 3 ========\n",
      "Average training loss: 0.23801673366688192\n",
      "Validation loss: 0.21559936832636595, Validation Accuracy:0.94140625\n",
      "======== Epoch 2 / 3 ========\n",
      "Average training loss: 0.14772493984977095\n",
      "Validation loss: 0.23957718384917825, Validation Accuracy:0.9375\n",
      "======== Epoch 3 / 3 ========\n",
      "Average training loss: 0.10960884498652174\n",
      "Validation loss: 0.2458496591716539, Validation Accuracy:0.94140625\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 3\n",
    "\n",
    "# multi-step learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,50,80], gamma=0.1, verbose=True)\n",
    "\n",
    "# Training and evaluation loop\n",
    "for epoch in range(epochs):\n",
    "    print(\"======== Epoch {:} / {:} ========\".format(epoch + 1, epochs))\n",
    "    avg_train_loss = train(model, train_dataloader, optimizer, device)\n",
    "    print(f\"Average training loss: {avg_train_loss}\")\n",
    "\n",
    "    avg_val_loss, avg_val_acc = evaluate(model, validation_dataloader, device)\n",
    "    print(f\"Validation loss: {avg_val_loss}, Validation Accuracy:{avg_val_acc}\")\n",
    "    # Print validation accuracy if you are calculating it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
